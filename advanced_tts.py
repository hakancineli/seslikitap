"""
GeliÅŸmiÅŸ TTS Ã–zellikleri
- KonuÅŸma stili uyarlama (hÄ±z, ton, vurgu)
- GeliÅŸmiÅŸ kontroller
- Ses karÄ±ÅŸtÄ±rma
"""
from TTS.api import TTS
import torch
from pydub import AudioSegment
import os
import numpy as np
import soundfile as sf


class AdvancedTTS:
    """GeliÅŸmiÅŸ TTS Ã¶zellikleri"""
    
    def __init__(self, voice_sample_path: str):
        self.device = "cpu"
        self.voice_sample = voice_sample_path
        
        print("ðŸ“¥ XTTS v2 modeli yÃ¼kleniyor (GeliÅŸmiÅŸ Ã–zellikler)...")
        self.tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(self.device)
        print("âœ… Model yÃ¼klendi!")
    
    def generate_with_style(
        self,
        text: str,
        output_path: str,
        speed: float = 1.0,
        emotion: str = "neutral",
        pitch_shift: int = 0
    ) -> bool:
        """
        GeliÅŸmiÅŸ stil kontrolÃ¼ ile ses Ã¼retimi
        
        Args:
            text: Metin
            output_path: Ã‡Ä±ktÄ± dosyasÄ±
            speed: KonuÅŸma hÄ±zÄ± (0.5-2.0, 1.0=normal)
            emotion: Duygu tonu (neutral, happy, sad, excited)
            pitch_shift: Ses tonu kaydÄ±rma (-5 to +5)
        """
        
        try:
            print(f"\nðŸŽ­ GeliÅŸmiÅŸ Ãœretim:")
            print(f"   ðŸ“ Metin: {text[:50]}...")
            print(f"   âš¡ HÄ±z: {speed}x")
            print(f"   ðŸŽ­ Duygu: {emotion}")
            print(f"   ðŸŽµ Ton: {pitch_shift:+d}")
            
            # Temel TTS Ã¼retimi
            temp_output = output_path.replace('.wav', '_temp.wav')
            
            self.tts.tts_to_file(
                text=text,
                speaker_wav=self.voice_sample,
                language="tr",
                file_path=temp_output
            )
            
            # Ses dosyasÄ±nÄ± yÃ¼kle
            audio = AudioSegment.from_wav(temp_output)
            
            # HIZ AYARI
            if speed != 1.0:
                print(f"   âš¡ HÄ±z ayarlanÄ±yor: {speed}x")
                # HÄ±zÄ± deÄŸiÅŸtir (frame rate manipÃ¼lasyonu)
                new_sample_rate = int(audio.frame_rate * speed)
                audio = audio._spawn(audio.raw_data, overrides={
                    "frame_rate": new_sample_rate
                }).set_frame_rate(audio.frame_rate)
            
            # TON AYARI (Pitch Shift)
            if pitch_shift != 0:
                print(f"   ðŸŽµ Ton kaydÄ±rÄ±lÄ±yor: {pitch_shift:+d}")
                # Octave deÄŸiÅŸimi (her +1 = yarÄ±m oktav yukarÄ±)
                octaves = pitch_shift * 0.1  # Daha hassas kontrol
                new_sample_rate = int(audio.frame_rate * (2.0 ** octaves))
                audio = audio._spawn(audio.raw_data, overrides={
                    "frame_rate": new_sample_rate
                }).set_frame_rate(audio.frame_rate)
            
            # DUYGU TONU (basit amplitÃ¼d manipÃ¼lasyonu)
            if emotion == "excited":
                print(f"   ðŸŽ­ HeyecanlÄ± ton ekleniyor...")
                audio = audio + 2  # Biraz daha yÃ¼ksek ses
            elif emotion == "sad":
                print(f"   ðŸŽ­ ÃœzgÃ¼n ton ekleniyor...")
                audio = audio - 2  # Biraz daha dÃ¼ÅŸÃ¼k ses
            elif emotion == "happy":
                print(f"   ðŸŽ­ Mutlu ton ekleniyor...")
                audio = audio + 1
            
            # Normalize et
            audio = audio.normalize()
            
            # Kaydet
            audio.export(output_path, format="wav")
            
            # Temp dosyayÄ± sil
            if os.path.exists(temp_output):
                os.remove(temp_output)
            
            print(f"   âœ… BaÅŸarÄ±lÄ±: {output_path}")
            return True
            
        except Exception as e:
            print(f"   âŒ Hata: {e}")
            return False
    
    @staticmethod
    def blend_voices(
        voice1_path: str,
        voice2_path: str,
        output_path: str,
        blend_ratio: float = 0.5
    ) -> str:
        """
        Ä°ki sesi karÄ±ÅŸtÄ±r (Voice Blending)
        
        Args:
            voice1_path: Ä°lk ses dosyasÄ±
            voice2_path: Ä°kinci ses dosyasÄ±
            output_path: Ã‡Ä±ktÄ± dosyasÄ±
            blend_ratio: KarÄ±ÅŸÄ±m oranÄ± (0.0=sadece voice1, 1.0=sadece voice2, 0.5=eÅŸit)
        
        Returns:
            Ã‡Ä±ktÄ± dosya yolu
        """
        
        print(f"\nðŸŽ¨ SES KARIÅžTIRMA:")
        print(f"   ðŸŽ¤ Ses 1: {voice1_path}")
        print(f"   ðŸŽ¤ Ses 2: {voice2_path}")
        print(f"   ðŸŽšï¸  Oran: {blend_ratio:.1%} (Ses 2)")
        
        # Ses dosyalarÄ±nÄ± yÃ¼kle
        data1, sr1 = sf.read(voice1_path)
        data2, sr2 = sf.read(voice2_path)
        
        # Sample rate eÅŸitle
        if sr1 != sr2:
            print(f"   âš ï¸  Sample rate eÅŸitleniyor: {sr1} vs {sr2}")
            # BasitleÅŸtirilmiÅŸ: daha kÄ±sa olanÄ± kullan
            sr_target = min(sr1, sr2)
            if sr1 != sr_target:
                # Resample data1
                ratio = sr_target / sr1
                new_length = int(len(data1) * ratio)
                data1 = np.interp(
                    np.linspace(0, len(data1), new_length),
                    np.arange(len(data1)),
                    data1
                )
                sr1 = sr_target
            if sr2 != sr_target:
                # Resample data2
                ratio = sr_target / sr2
                new_length = int(len(data2) * ratio)
                data2 = np.interp(
                    np.linspace(0, len(data2), new_length),
                    np.arange(len(data2)),
                    data2
                )
                sr2 = sr_target
        
        # UzunluklarÄ± eÅŸitle (daha kÄ±sa olanÄ± kullan)
        min_length = min(len(data1), len(data2))
        data1 = data1[:min_length]
        data2 = data2[:min_length]
        
        # KarÄ±ÅŸtÄ±r
        blended = data1 * (1 - blend_ratio) + data2 * blend_ratio
        
        # Normalize
        blended = blended / np.max(np.abs(blended)) * 0.95
        
        # Kaydet
        sf.write(output_path, blended, sr1)
        
        print(f"   âœ… KarÄ±ÅŸÄ±k ses oluÅŸturuldu: {output_path}")
        print(f"   â±ï¸  SÃ¼re: {len(blended)/sr1:.1f} saniye")
        
        return output_path


def test_advanced_features():
    """GeliÅŸmiÅŸ Ã¶zellikleri test et"""
    
    print("\n" + "="*60)
    print("ðŸ§ª GELÄ°ÅžMÄ°Åž Ã–ZELLÄ°KLER TESTÄ°")
    print("="*60)
    
    voice_sample = "voices/akin_altan_optimized.wav"
    
    if not os.path.exists(voice_sample):
        print(f"âŒ Referans ses bulunamadÄ±: {voice_sample}")
        return
    
    tts = AdvancedTTS(voice_sample)
    
    # Test 1: Normal hÄ±z
    print("\n--- Test 1: Normal HÄ±z ---")
    tts.generate_with_style(
        "Bu normal hÄ±zda bir cÃ¼mledir.",
        "test_normal.wav",
        speed=1.0
    )
    
    # Test 2: YavaÅŸ
    print("\n--- Test 2: YavaÅŸ KonuÅŸma ---")
    tts.generate_with_style(
        "Bu yavaÅŸ bir cÃ¼mledir.",
        "test_slow.wav",
        speed=0.7
    )
    
    # Test 3: HÄ±zlÄ±
    print("\n--- Test 3: HÄ±zlÄ± KonuÅŸma ---")
    tts.generate_with_style(
        "Bu hÄ±zlÄ± bir cÃ¼mledir.",
        "test_fast.wav",
        speed=1.3
    )
    
    # Test 4: YÃ¼ksek ton
    print("\n--- Test 4: YÃ¼ksek Ton ---")
    tts.generate_with_style(
        "Bu yÃ¼ksek tonlu bir cÃ¼mledir.",
        "test_high_pitch.wav",
        speed=1.0,
        pitch_shift=3
    )
    
    # Test 5: DÃ¼ÅŸÃ¼k ton
    print("\n--- Test 5: DÃ¼ÅŸÃ¼k Ton ---")
    tts.generate_with_style(
        "Bu dÃ¼ÅŸÃ¼k tonlu bir cÃ¼mledir.",
        "test_low_pitch.wav",
        speed=1.0,
        pitch_shift=-3
    )
    
    print("\n" + "="*60)
    print("âœ… TESTLER TAMAMLANDI!")
    print("="*60)
    print("\nðŸŽ§ Dinlemek iÃ§in:")
    print("   open test_normal.wav")
    print("   open test_slow.wav")
    print("   open test_fast.wav")
    print("   open test_high_pitch.wav")
    print("   open test_low_pitch.wav")
    print("="*60)


def test_voice_blending():
    """Ses karÄ±ÅŸtÄ±rmayÄ± test et"""
    
    print("\n" + "="*60)
    print("ðŸ§ª SES KARIÅžTIRMA TESTÄ°")
    print("="*60)
    
    voice1 = "voices/akin_altan_optimized.wav"
    voice2 = "voices/benim_sesim.wav"
    
    if not os.path.exists(voice1) or not os.path.exists(voice2):
        print("âŒ Ses dosyalarÄ± bulunamadÄ±!")
        print(f"   Voice 1: {voice1}")
        print(f"   Voice 2: {voice2}")
        return
    
    # %25 voice2, %75 voice1
    AdvancedTTS.blend_voices(voice1, voice2, "blended_25.wav", 0.25)
    
    # %50-%50
    AdvancedTTS.blend_voices(voice1, voice2, "blended_50.wav", 0.5)
    
    # %75 voice2, %25 voice1
    AdvancedTTS.blend_voices(voice1, voice2, "blended_75.wav", 0.75)
    
    print("\n" + "="*60)
    print("âœ… KARIÅžIK SESLER OLUÅžTURULDU!")
    print("="*60)
    print("\nðŸŽ§ Dinlemek iÃ§in:")
    print("   open blended_25.wav  # %75 AkÄ±n ALTAN + %25 Senin Sesin")
    print("   open blended_50.wav  # %50-%50 KarÄ±ÅŸÄ±k")
    print("   open blended_75.wav  # %25 AkÄ±n ALTAN + %75 Senin Sesin")
    print("="*60)


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "blend":
        test_voice_blending()
    else:
        test_advanced_features()




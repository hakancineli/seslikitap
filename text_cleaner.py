"""
Metin Temizleme - TTS iÃ§in metin normalleÅŸtirme
"""
import unicodedata
import re


class TextCleaner:
    """Metni TTS iÃ§in temizle ve normalize et"""
    
    @staticmethod
    def remove_diacritics(text: str) -> str:
        """
        Diacritics (aksanlar, Ã¶zel iÅŸaretler) kaldÄ±r
        Ã–rnek: áº• â†’ z, Ã¡ â†’ a, Ã± â†’ n
        
        ANCAK TÃ¼rkÃ§e karakterleri koru: ÅŸ, ÄŸ, Ã¼, Ã¶, Ã§, Ä±
        """
        # TÃ¼rkÃ§e karakterleri geÃ§ici olarak koru
        turkish_chars = {
            'ÅŸ': '___TURKISH_S___',
            'Å': '___TURKISH_S_UPPER___',
            'ÄŸ': '___TURKISH_G___',
            'Ä': '___TURKISH_G_UPPER___',
            'Ã¼': '___TURKISH_U___',
            'Ãœ': '___TURKISH_U_UPPER___',
            'Ã¶': '___TURKISH_O___',
            'Ã–': '___TURKISH_O_UPPER___',
            'Ã§': '___TURKISH_C___',
            'Ã‡': '___TURKISH_C_UPPER___',
            'Ä±': '___TURKISH_I___',
            'Ä°': '___TURKISH_I_UPPER___',
        }
        
        # TÃ¼rkÃ§e karakterleri deÄŸiÅŸtir
        for char, placeholder in turkish_chars.items():
            text = text.replace(char, placeholder)
        
        # NFD decomposition - aksanlarÄ± ayÄ±r
        text = unicodedata.normalize('NFD', text)
        
        # Combining characters'larÄ± (aksanlarÄ±) kaldÄ±r
        text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')
        
        # NFC composition - tekrar birleÅŸtir
        text = unicodedata.normalize('NFC', text)
        
        # TÃ¼rkÃ§e karakterleri geri getir
        for char, placeholder in turkish_chars.items():
            text = text.replace(placeholder, char)
        
        return text
    
    @staticmethod
    def normalize_whitespace(text: str) -> str:
        """BoÅŸluklarÄ± normalize et"""
        # Birden fazla boÅŸluÄŸu tek boÅŸluÄŸa Ã§evir
        text = re.sub(r'\s+', ' ', text)
        # BaÅŸta ve sonda boÅŸluk kaldÄ±r
        text = text.strip()
        return text
    
    @staticmethod
    def remove_special_characters(text: str) -> str:
        """
        TTS iÃ§in sorunlu Ã¶zel karakterleri kaldÄ±r
        Ama noktalama iÅŸaretlerini koru (. , ! ? : ; - ...)
        """
        # Ä°zin verilen karakterler: harfler, sayÄ±lar, temel noktalama
        # TÃ¼rkÃ§e karakterler de dahil
        allowed_pattern = r'[^a-zA-ZÅŸÄŸÃ¼Ã¶Ã§Ä±Ä°ÅÄÃœÃ–Ã‡0-9\s.,!?:;\-â€”â€“\'\"()\[\]â€¦]'
        text = re.sub(allowed_pattern, '', text)
        return text
    
    @staticmethod
    def fix_common_issues(text: str) -> str:
        """YaygÄ±n sorunlarÄ± dÃ¼zelt"""
        # Birden fazla nokta iÅŸaretini Ã¼Ã§ noktaya Ã§evir
        text = re.sub(r'\.{4,}', '...', text)
        
        # Noktalama iÅŸaretlerinden Ã¶nce boÅŸluk kaldÄ±r
        text = re.sub(r'\s+([.,!?:;])', r'\1', text)
        
        # Noktalama iÅŸaretlerinden sonra boÅŸluk ekle (yoksa)
        text = re.sub(r'([.,!?:;])([^\s])', r'\1 \2', text)
        
        return text
    
    @staticmethod
    def clean_text(text: str, verbose: bool = False) -> str:
        """
        Metni TTS iÃ§in kapsamlÄ± temizle
        
        Args:
            text: Ham metin
            verbose: Debug Ã§Ä±ktÄ±sÄ± gÃ¶ster
            
        Returns:
            TemizlenmiÅŸ metin
        """
        if verbose:
            print("\n" + "="*60)
            print("ğŸ§¹ METÄ°N TEMÄ°ZLEME")
            print("="*60)
            print(f"ğŸ“ Orijinal ({len(text)} karakter):")
            print(f"   {text[:200]}...")
        
        # 1. Diacritics (aksanlar) temizle
        text = TextCleaner.remove_diacritics(text)
        if verbose:
            print(f"\nâœ“ Aksanlar temizlendi")
        
        # 2. Ã–zel karakterleri temizle
        text = TextCleaner.remove_special_characters(text)
        if verbose:
            print(f"âœ“ Ã–zel karakterler kaldÄ±rÄ±ldÄ±")
        
        # 3. BoÅŸluklarÄ± normalize et
        text = TextCleaner.normalize_whitespace(text)
        if verbose:
            print(f"âœ“ BoÅŸluklar normalize edildi")
        
        # 4. YaygÄ±n sorunlarÄ± dÃ¼zelt
        text = TextCleaner.fix_common_issues(text)
        if verbose:
            print(f"âœ“ YaygÄ±n sorunlar dÃ¼zeltildi")
        
        if verbose:
            print(f"\nğŸ“ TemizlenmiÅŸ ({len(text)} karakter):")
            print(f"   {text[:200]}...")
            print("="*60)
        
        return text


def test_cleaner():
    """Test fonksiyonu"""
    test_texts = [
        "Her insanÄ±n bir hikÃ¢yesi vardÄ±r",  # Normal
        "BazÄ± kelimeler áº• harfi ile yazÄ±lmÄ±ÅŸ",  # zÌ„ problemi
        "Ã‡ok    fazla       boÅŸluk",  # BoÅŸluk problemi
        "TÃ¼rkÃ§e karakterler: ÅŸÄŸÃ¼Ã¶Ã§Ä±Ä°",  # TÃ¼rkÃ§e karakterler korunmalÄ±
        "Ã–zel@#$%karakterler&*() burada",  # Ã–zel karakterler
    ]
    
    print("\n" + "="*60)
    print("ğŸ§ª METÄ°N TEMÄ°ZLEME TESTÄ°")
    print("="*60)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\n{i}. Test:")
        print(f"   Ã–nce:  {text}")
        cleaned = TextCleaner.clean_text(text)
        print(f"   Sonra: {cleaned}")
    
    print("\n" + "="*60)


if __name__ == "__main__":
    test_cleaner()




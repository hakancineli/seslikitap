"""
Metin Temizleme - TTS iÃ§in metin normalleÅŸtirme
"""
import unicodedata
import re
from typing import Dict


class TurkishTextPreprocessor:
    """TÃ¼rkÃ§e TTS iÃ§in Ã¶zel metin Ã¶n iÅŸleme"""
    
    # TÃ¼rkÃ§e kÄ±saltmalar
    TURKISH_ABBREVIATIONS: Dict[str, str] = {
        'vb.': 've benzeri',
        'vs.': 've saire',
        'vd.': 've diÄŸerleri',
        'Prof.': 'ProfesÃ¶r',
        'Dr.': 'Doktor',
        'Yrd.': 'YardÄ±mcÄ±',
        'DoÃ§.': 'DoÃ§ent',
        'Av.': 'Avukat',
        'Muh.': 'Muhendis',
        'Ltd.': 'Limited',
        'Åti.': 'Åirketi',
        'A.Å.': 'Anonim Åirket',
        'Hz.': 'Hazretleri',
        'Ã–.': 'Ã–lÃ¼mÃ¼',
        'D.': 'DoÄŸumu',
        'No.': 'Numara',
        'Sok.': 'Sokak',
        'Cad.': 'Cadde',
        'Apt.': 'Apartman',
        'Tel.': 'Telefon',
        'Fax.': 'Faks',
        'Kat.': 'Kat',
        'S.': 'Sayfa',
        'bkz.': 'bakÄ±nÄ±z',
        'krÅŸ.': 'karÅŸÄ±laÅŸtÄ±rÄ±nÄ±z',
        'Ã¶rn.': 'Ã¶rneÄŸin',
        'yak.': 'yaklaÅŸÄ±k'
    }
    
    # SayÄ±lar iÃ§in TÃ¼rkÃ§e kelimeler
    ONES = ['', 'bir', 'iki', 'Ã¼Ã§', 'dÃ¶rt', 'beÅŸ', 'altÄ±', 'yedi', 'sekiz', 'dokuz']
    TENS = ['', 'on', 'yirmi', 'otuz', 'kÄ±rk', 'elli', 'altmÄ±ÅŸ', 'yetmiÅŸ', 'seksen', 'doksan']
    HUNDREDS = ['', 'yÃ¼z', 'ikiyÃ¼z', 'Ã¼Ã§yÃ¼z', 'dÃ¶rtyÃ¼z', 'beÅŸyÃ¼z', 'altÄ±yÃ¼z', 'yediyÃ¼z', 'sekizyÃ¼z', 'dokuzyÃ¼z']
    
    @classmethod
    def expand_abbreviations(cls, text: str) -> str:
        """KÄ±saltmalarÄ± aÃ§"""
        for abbr, expansion in cls.TURKISH_ABBREVIATIONS.items():
            # Case-insensitive replacement
            text = re.sub(re.escape(abbr), expansion, text, flags=re.IGNORECASE)
        return text
    
    @classmethod
    def number_to_words(cls, num: int) -> str:
        """
        SayÄ±yÄ± TÃ¼rkÃ§e kelimeye Ã§evir (0-999)
        
        Ã–rnekler:
            123 â†’ 'yÃ¼z yirmi Ã¼Ã§'
            45 â†’ 'kÄ±rk beÅŸ'
            7 â†’ 'yedi'
        """
        if num == 0:
            return 'sÄ±fÄ±r'
        
        if num < 0:
            return 'eksi ' + cls.number_to_words(abs(num))
        
        if num >= 1000:
            # BÃ¼yÃ¼k sayÄ±lar iÃ§in basit strateji
            return str(num)  # Veya daha kompleks bir Ã§Ã¶zÃ¼m eklenebilir
        
        result = []
        
        # YÃ¼zler
        hundreds = num // 100
        if hundreds > 0:
            if hundreds == 1:
                result.append('yÃ¼z')
            else:
                result.append(cls.HUNDREDS[hundreds])
        
        # Onlar
        tens = (num % 100) // 10
        if tens > 0:
            result.append(cls.TENS[tens])
        
        # Birler
        ones = num % 10
        if ones > 0:
            result.append(cls.ONES[ones])
        
        return ' '.join(result)
    
    @classmethod
    def convert_numbers_to_words(cls, text: str) -> str:
        """Metindeki sayÄ±larÄ± kelimelere Ã§evir"""
        def replace_number(match):
            num_str = match.group(0)
            try:
                num = int(num_str)
                if 0 <= num < 1000:
                    return cls.number_to_words(num)
                else:
                    return num_str  # BÃ¼yÃ¼k sayÄ±larÄ± olduÄŸu gibi bÄ±rak
            except ValueError:
                return num_str
        
        # Sadece tek baÅŸÄ±na duran sayÄ±larÄ± deÄŸiÅŸtir
        text = re.sub(r'\b\d+\b', replace_number, text)
        return text
    
    @classmethod
    def preprocess_for_tts(cls, text: str, convert_numbers: bool = True) -> str:
        """
        TÃ¼rkÃ§e metni TTS iÃ§in Ã¶n iÅŸle
        
        Args:
            text: Ham metin
            convert_numbers: SayÄ±larÄ± kelimelere Ã§evir
            
        Returns:
            Ä°ÅŸlenmiÅŸ metin
        """
        # 1. KÄ±saltmalarÄ± aÃ§
        text = cls.expand_abbreviations(text)
        
        # 2. SayÄ±larÄ± kelimelere Ã§evir (isteÄŸe baÄŸlÄ±)
        if convert_numbers:
            text = cls.convert_numbers_to_words(text)
        
        return text


class TextCleaner:
    """Metni TTS iÃ§in temizle ve normalize et"""
    
    @staticmethod
    def remove_diacritics(text: str) -> str:
        """
        Diacritics (aksanlar, Ã¶zel iÅŸaretler) kaldÄ±r
        Ã–rnek: áº• â†’ z, Ã¡ â†’ a, Ã± â†’ n
        
        ANCAK TÃ¼rkÃ§e karakterleri koru: ÅŸ, ÄŸ, Ã¼, Ã¶, Ã§, Ä±
        """
        # TÃ¼rkÃ§e karakterleri geÃ§ici olarak koru
        turkish_chars = {
            'ÅŸ': '___TURKISH_S___',
            'Å': '___TURKISH_S_UPPER___',
            'ÄŸ': '___TURKISH_G___',
            'Ä': '___TURKISH_G_UPPER___',
            'Ã¼': '___TURKISH_U___',
            'Ãœ': '___TURKISH_U_UPPER___',
            'Ã¶': '___TURKISH_O___',
            'Ã–': '___TURKISH_O_UPPER___',
            'Ã§': '___TURKISH_C___',
            'Ã‡': '___TURKISH_C_UPPER___',
            'Ä±': '___TURKISH_I___',
            'Ä°': '___TURKISH_I_UPPER___',
        }
        
        # TÃ¼rkÃ§e karakterleri deÄŸiÅŸtir
        for char, placeholder in turkish_chars.items():
            text = text.replace(char, placeholder)
        
        # NFD decomposition - aksanlarÄ± ayÄ±r
        text = unicodedata.normalize('NFD', text)
        
        # Combining characters'larÄ± (aksanlarÄ±) kaldÄ±r
        text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')
        
        # NFC composition - tekrar birleÅŸtir
        text = unicodedata.normalize('NFC', text)
        
        # TÃ¼rkÃ§e karakterleri geri getir
        for char, placeholder in turkish_chars.items():
            text = text.replace(placeholder, char)
        
        return text
    
    @staticmethod
    def normalize_whitespace(text: str) -> str:
        """BoÅŸluklarÄ± normalize et"""
        # Birden fazla boÅŸluÄŸu tek boÅŸluÄŸa Ã§evir
        text = re.sub(r'\s+', ' ', text)
        # BaÅŸta ve sonda boÅŸluk kaldÄ±r
        text = text.strip()
        return text
    
    @staticmethod
    def remove_special_characters(text: str) -> str:
        """
        TTS iÃ§in sorunlu Ã¶zel karakterleri kaldÄ±r
        Ama noktalama iÅŸaretlerini koru (. , ! ? : ; - ...)
        """
        # Ä°zin verilen karakterler: harfler, sayÄ±lar, temel noktalama
        # TÃ¼rkÃ§e karakterler de dahil
        allowed_pattern = r'[^a-zA-ZÅŸÄŸÃ¼Ã¶Ã§Ä±Ä°ÅÄÃœÃ–Ã‡0-9\s.,!?:;\-â€”â€“\'\"()\[\]â€¦]'
        text = re.sub(allowed_pattern, '', text)
        return text
    
    @staticmethod
    def fix_common_issues(text: str) -> str:
        """YaygÄ±n sorunlarÄ± dÃ¼zelt"""
        # Birden fazla nokta iÅŸaretini Ã¼Ã§ noktaya Ã§evir
        text = re.sub(r'\.{4,}', '...', text)
        
        # Noktalama iÅŸaretlerinden Ã¶nce boÅŸluk kaldÄ±r
        text = re.sub(r'\s+([.,!?:;])', r'\1', text)
        
        # Noktalama iÅŸaretlerinden sonra boÅŸluk ekle (yoksa)
        text = re.sub(r'([.,!?:;])([^\s])', r'\1 \2', text)
        
        return text
    
    @staticmethod
    def clean_text(text: str, verbose: bool = False, turkish_preprocess: bool = True) -> str:
        """
        Metni TTS iÃ§in kapsamlÄ± temizle
        
        Args:
            text: Ham metin
            verbose: Debug Ã§Ä±ktÄ±sÄ± gÃ¶ster
            turkish_preprocess: TÃ¼rkÃ§e Ã¶n iÅŸleme uygula
            
        Returns:
            TemizlenmiÅŸ metin
        """
        if verbose:
            print("\n" + "="*60)
            print("ğŸ§¹ METÄ°N TEMÄ°ZLEME")
            print("="*60)
            print(f"ğŸ“ Orijinal ({len(text)} karakter):")
            print(f"   {text[:200]}...")
        
        # 0. TÃ¼rkÃ§e Ã¶n iÅŸleme (kÄ±saltmalar, sayÄ±lar)
        if turkish_preprocess:
            text = TurkishTextPreprocessor.preprocess_for_tts(text)
            if verbose:
                print(f"\nâœ“ TÃ¼rkÃ§e Ã¶n iÅŸleme tamamlandÄ±")
        
        # 1. Diacritics (aksanlar) temizle
        text = TextCleaner.remove_diacritics(text)
        if verbose:
            print(f"âœ“ Aksanlar temizlendi")
        
        # 2. Ã–zel karakterleri temizle
        text = TextCleaner.remove_special_characters(text)
        if verbose:
            print(f"âœ“ Ã–zel karakterler kaldÄ±rÄ±ldÄ±")
        
        # 3. BoÅŸluklarÄ± normalize et
        text = TextCleaner.normalize_whitespace(text)
        if verbose:
            print(f"âœ“ BoÅŸluklar normalize edildi")
        
        # 4. YaygÄ±n sorunlarÄ± dÃ¼zelt
        text = TextCleaner.fix_common_issues(text)
        if verbose:
            print(f"âœ“ YaygÄ±n sorunlar dÃ¼zeltildi")
        
        if verbose:
            print(f"\nğŸ“ TemizlenmiÅŸ ({len(text)} karakter):")
            print(f"   {text[:200]}...")
            print("="*60)
        
        return text


def test_cleaner():
    """Test fonksiyonu"""
    test_texts = [
        "Her insanÄ±n bir hikÃ¢yesi vardÄ±r",  # Normal
        "BazÄ± kelimeler áº• harfi ile yazÄ±lmÄ±ÅŸ",  # zÌ„ problemi
        "Ã‡ok    fazla       boÅŸluk",  # BoÅŸluk problemi
        "TÃ¼rkÃ§e karakterler: ÅŸÄŸÃ¼Ã¶Ã§Ä±Ä°",  # TÃ¼rkÃ§e karakterler korunmalÄ±
        "Ã–zel@#$%karakterler&*() burada",  # Ã–zel karakterler
        "Prof. Dr. Ali 25 yaÅŸÄ±nda vb.",  # KÄ±saltmalar ve sayÄ±lar
        "No. 123 Sok. Apt. 5 Kat",  # KÄ±saltmalar ve sayÄ±lar
    ]
    
    print("\n" + "="*60)
    print("ğŸ§ª METÄ°N TEMÄ°ZLEME TESTÄ°")
    print("="*60)
    
    for i, text in enumerate(test_texts, 1):
        print(f"\n{i}. Test:")
        print(f"   Ã–nce:  {text}")
        cleaned = TextCleaner.clean_text(text)
        print(f"   Sonra: {cleaned}")
    
    print("\n" + "="*60)
    
    # TÃ¼rkÃ§e Ã¶n iÅŸleme testi
    print("\n" + "="*60)
    print("ğŸ§ª TÃœRKÃ‡E Ã–N Ä°ÅLEME TESTÄ°")
    print("="*60)
    
    turkish_tests = [
        ("Prof. Dr. Ali", "ProfesÃ¶r Doktor Ali"),
        ("No. 5 vb.", "Numara beÅŸ ve benzeri"),
        ("123", "yÃ¼z yirmi Ã¼Ã§"),
        ("45 yÄ±l", "kÄ±rk beÅŸ yÄ±l"),
    ]
    
    for i, (input_text, expected) in enumerate(turkish_tests, 1):
        processed = TurkishTextPreprocessor.preprocess_for_tts(input_text)
        print(f"\n{i}. Test:")
        print(f"   Girdi:    {input_text}")
        print(f"   Ã‡Ä±ktÄ±:    {processed}")
        print(f"   Beklenen: {expected}")
        print(f"   âœ“" if processed.lower() == expected.lower() else "   âœ—")
    
    print("\n" + "="*60)


if __name__ == "__main__":
    test_cleaner()



